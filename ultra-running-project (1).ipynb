{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":6123935,"datasetId":3417125,"databundleVersionId":6202644}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project description\nThis project uses the The Big Dataset of Ultra Marathon Running to explore long distance running performances and build a predictive model.\nThe goal is to use the full historical dataset to train a model that can predict the finishing time of runners in a chosen race, but only for athletes who have previous race results recorded in the dataset.\n\nUltra marathons vary greatly in distance, terrain, and difficulty. Runners often participate in many races over multiple years. \nThis project focuses on:\n\ncleaning and standardizing the large dataset\n\nanalyzing athlete histories\n\nengineering features such as race difficulty and runner consistency\n\ntraining a model using global trends while giving extra importance to each runner’s past performances\n\nThe model will be used to predict the finishing times of runners in the 2022 Western States Ultra Endurance Run.","metadata":{}},{"cell_type":"code","source":"# 1_load.py\nimport pandas as pd\n\ndef load_raw_data(path: str) -> pd.DataFrame:\n    \"\"\"Load the raw ultramarathon dataset.\"\"\"\n    return pd.read_csv(path, low_memory=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:41:15.744639Z","iopub.execute_input":"2025-12-17T05:41:15.745583Z","iopub.status.idle":"2025-12-17T05:41:15.750762Z","shell.execute_reply.started":"2025-12-17T05:41:15.745551Z","shell.execute_reply":"2025-12-17T05:41:15.749747Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"#EDA keep seperate from pipeline\nPATH = \"/kaggle/input/the-big-dataset-of-ultra-marathon-running/TWO_CENTURIES_OF_UM_RACES.csv\"\ndf_raw = pd.read_csv(PATH, low_memory=False)\n\nprint(df_raw.shape)\ndf_raw.head()\ndf_raw.isna().sum()\n\nprint(\"Shape: \", df_raw.shape)\nprint(\"Head: \", df_raw.head())\nprint(df_raw.isna().sum())\n\n\ndef clean_event_name(name):\n    if not isinstance(name, str):\n        return name\n    \n    # 1. Lowercase for standardization\n    name = name.lower()\n    \n    # 2. Remove year (19xx or 20xx) regardless of where it is\n    # Handles 2018, (2018), 9ª (edition numbers)\n    name = re.sub(r'\\(?\\b(19|20)\\d{2}\\b\\)?', '', name)\n    name = re.sub(r'\\d+ª', '', name) \n    \n    # 3. Remove country codes in brackets like (GER), (USA), (ESP)\n    name = re.sub(r'\\([a-z]{3}\\)', '', name)\n    \n    # 4. Remove Distance/Stage noise\n    # Strips \"100km\", \"50 mile\", \"6 hour\", \"etappe\", \"kidsrun\"\n    noise_patterns = [\n        r'\\d+\\s*(km|k|miles|mile|mi|h|hr|hour|hours|stunden|óra|órás)\\b',\n        r'etappe[:\\s]\\d+',\n        r'kidsrun',\n        r'winter challenge',\n        r'trail race',\n        r'road race'\n    ]\n    for pattern in noise_patterns:\n        name = re.sub(pattern, '', name)\n\n    # 5. Clean up symbols and extra whitespace\n    name = re.sub(r'[^a-z\\s]', ' ', name) # Remove everything except letters and spaces\n    name = re.sub(r'\\s+', ' ', name).strip()\n    \n    return name\n    \ndf_raw['Event_name_clean'] = df_raw['Event name'].apply(clean_event_name)\n\nprint(df_raw['Event_name_clean'].unique()[:20])\n\n# Look for names that definitely contain 4 digits (likely years)\nsample_years = df_raw[df_raw['Event_name_clean'].str.contains(r'\\d{4}', na=False)]['Event_name_clean'].unique()[:10]\nprint(\"\\nNames containing digits:\")\nprint(sample_years)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:50:43.884418Z","iopub.execute_input":"2025-12-17T05:50:43.884748Z","iopub.status.idle":"2025-12-17T05:52:49.478507Z","shell.execute_reply.started":"2025-12-17T05:50:43.884718Z","shell.execute_reply":"2025-12-17T05:52:49.477412Z"}},"outputs":[{"name":"stdout","text":"(7461195, 13)\nShape:  (7461195, 13)\nHead:     Year of event Event dates           Event name Event distance/length  \\\n0           2018  06.01.2018  Selva Costera (CHI)                  50km   \n1           2018  06.01.2018  Selva Costera (CHI)                  50km   \n2           2018  06.01.2018  Selva Costera (CHI)                  50km   \n3           2018  06.01.2018  Selva Costera (CHI)                  50km   \n4           2018  06.01.2018  Selva Costera (CHI)                  50km   \n\n   Event number of finishers Athlete performance        Athlete club  \\\n0                         22           4:51:39 h               Tnfrc   \n1                         22           5:15:45 h  Roberto Echeverría   \n2                         22           5:16:44 h   Puro Trail Osorno   \n3                         22           5:34:13 h            Columbia   \n4                         22           5:54:14 h      Baguales Trail   \n\n  Athlete country  Athlete year of birth Athlete gender Athlete age category  \\\n0             CHI                 1978.0              M                  M35   \n1             CHI                 1981.0              M                  M35   \n2             CHI                 1987.0              M                  M23   \n3             ARG                 1976.0              M                  M40   \n4             CHI                 1992.0              M                  M23   \n\n  Athlete average speed  Athlete ID  \n0                10.286           0  \n1                 9.501           1  \n2                 9.472           2  \n3                 8.976           3  \n4                 8.469           4  \nYear of event                      0\nEvent dates                        0\nEvent name                         0\nEvent distance/length           1053\nEvent number of finishers          0\nAthlete performance                2\nAthlete club                 2826524\nAthlete country                    3\nAthlete year of birth         588161\nAthlete gender                     7\nAthlete age category          584938\nAthlete average speed            224\nAthlete ID                         0\ndtype: int64\n['selva costera' 'self transcendence sri chinmoy smolensk'\n 'knap trail forhajerska' 'yankee springs' 'la cuesta ranch trail run'\n 'frozen sasquatch' 'watchung winter run' 'duinhopper' 's ultra'\n 'flaming mountain ultra run' 'sandman' 'hardmoors' 'the first walk'\n 'red eye' 'wujhihshan ultra run' 'shenzhen wutong new year trail'\n 'bayu twelve peaks nanshan trail' 'the silkin way ultra'\n 'pf lzer berglandtrail wolfstein potzberg wolfstein'\n 'f lbalaton supermarathon']\n\nNames containing digits:\n[]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Some event names contain years, sponsor names, or inconsistent formatting.\nMany missing distances match specific races that do not include distance in the name.\nThis motivated the later step of inferring numeric distance from textual patterns.","metadata":{}},{"cell_type":"code","source":"#Check which events have missing distances\ndf[df[\"Event distance/length\"].isna()][['Event name', 'Year of event']].drop_duplicates()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:02:07.307120Z","iopub.execute_input":"2025-12-12T13:02:07.307385Z","iopub.status.idle":"2025-12-12T13:02:07.316696Z","shell.execute_reply.started":"2025-12-12T13:02:07.307370Z","shell.execute_reply":"2025-12-12T13:02:07.315400Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/4031066630.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Check which events have missing distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Event distance/length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Event name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Year of event'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}],"execution_count":6},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"We removed Athlete club and Athlete country because they do not contribute to performance prediction and contain excessive missing values.\n\nWe dropped rows missing gender, year of birth, or age category because these represent essential physiological predictors of endurance performance, and imputing them would introduce bias.\n\nNext, see if we can infer Event distance/length from other features\n","metadata":{}},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\n\ndef clean_event_name(name):\n    if not isinstance(name, str):\n        return name\n    \n    # 1. Lowercase and basic strip\n    name = name.lower().strip()\n    \n    # 2. Remove year (19xx or 20xx) - Keep the distance!\n    # This removes 2018, (2018), etc. but leaves \"100km\"\n    name = re.sub(r'\\(?\\b(19|20)\\d{2}\\b\\)?', '', name)\n    \n    # 3. Remove country codes in brackets like (GER), (USA)\n    name = re.sub(r'\\([a-z]{3}\\)', '', name)\n    \n    # 4. Remove edition numbers (e.g., 9ª, 10th)\n    name = re.sub(r'\\d+(ª|th|st|nd|rd)', '', name)\n\n    # 6. Clean up symbols (keep numbers for the distances)\n    # We remove punctuation but keep alphanumeric so \"100km\" stays \"100km\"\n    name = re.sub(r'[^a-z0-9\\s]', ' ', name)\n    \n    # 7. Standardize spacing\n    name = re.sub(r'\\s+', ' ', name).strip()\n    \n    return name\n\ndef convert_to_seconds(time):\n    if 'd' in time:\n        days, time = time.split('d')\n        days = int(days)\n        time = time.strip()\n    else:\n        days = 0\n    h, m, s = map(int, time.split(':'))\n    return days * 86400 + h * 3600 + m * 60 + s\n\n\ndef clean_data(df):\n    \"\"\"\n    Clean ultra-marathon dataset:\n    - Drop weak/high-null columns\n    - Drop rows missing essential info\n    - Remove irrelevant events\n    - Clean 'Event distance/length' and convert to numeric km\n    - Correct specific event distance anomalies\n    - Remove athletes with conflicting gender data\n    - Clean and convert 'Athlete performance' to seconds\n    - Compute pace (min/km)\n    \"\"\"\n    \n    # Drop weak-value columns\n    df = df.drop(columns=['Athlete club', 'Athlete country'], errors='ignore')\n\n    # Drop rows missing critical fields\n    df = df.dropna(subset=[\n        \"Athlete gender\",\n        \"Athlete year of birth\",\n        \"Athlete age category\",\n        \"Athlete performance\"\n    ])\n    \n    # Remove irrelevant events\n    events_to_remove = [\n    \"Stockholm Fotrally \\\\(SWE\\\\)\",\n    \"Maratonmarschen Stockholm \\\\(SWE\\\\)\"\n    ]\n    df = df[~df['Event name'].str.contains('|'.join(events_to_remove), case=False)]\n\n    # Clean and convert 'Event distance/length' to numeric km\n    df['Event distance/length'] = df['Event distance/length'].astype(str).str.strip()\n    distance_str = df['Event distance/length'].str.lower().str.strip()\n    distance_clean = distance_str.str.replace('km', '').str.replace('k', '').str.strip()\n    \n    def extract_number(x):\n        match = re.search(r'\\d+(\\.\\d+)?', x)\n        if match:\n            return float(match.group())\n        return np.nan\n    distance_numeric = distance_clean.apply(extract_number)\n\n    # Convert miles to km\n    miles_mask = distance_clean.str.contains(r'm|mi|mile|miles', regex=True, case=False)\n    distance_numeric.loc[miles_mask] = distance_numeric.loc[miles_mask] * 1.60934\n\n    # Remove time-based or stage-based events\n    time_mask = distance_str.str.contains(r'h|hr|hour|hours|d|day|days|min', regex=True)\n    stage_mask = distance_str.str.contains(r'/|:|x', regex=True)\n    remove_mask = time_mask | stage_mask\n    df = df[~remove_mask].copy()\n\n    # Assign cleaned numeric distance\n    df['Event distance_numeric'] = distance_numeric.loc[df.index]\n\n    # Correct specific anomalous event distances\n    df.loc[df['Event name'] == \"Ultraroztocze 120km (POL)\", 'Event distance_numeric'] = 120\n    df.loc[df['Event name'] == \"Ultraroztocze 120km (POL)\", 'Event distance/length'] = '120km'\n\n    # Remove extreme distances (>250 km)\n    df = df[df['Event distance_numeric'].notna() & \n                    (df['Event distance_numeric'] <= 250)].copy()\n\n    # Remove athletes with multiple genders\n    gender_counts = df.groupby(\"Athlete ID\")[\"Athlete gender\"].nunique()\n    conflicting_ids = gender_counts[gender_counts > 1].index\n    df = df[~df[\"Athlete ID\"].isin(conflicting_ids)].copy()\n\n    # Clean 'Athlete performance' and convert to seconds\n    df['Athlete performance'] = df['Athlete performance'].astype(str).str.replace(' h', '').str.replace(' km', '')\n\n    pattern1 = r'^\\d{1,2}:\\d{2}:\\d{2}$'\n    pattern2 = r'^\\d+d \\d{2}:\\d{2}:\\d{2}$'\n    mask = df['Athlete performance'].apply(lambda x: bool(re.match(pattern1, x)) or bool(re.match(pattern2, x)))\n\n\n    df.loc[mask, 'time_in_seconds'] = df.loc[mask, 'Athlete performance'].apply(convert_to_seconds)\n\n    # Compute pace (min/km)\n    df['pace_min_per_km'] = (df['time_in_seconds'] / 60) / df['Event distance_numeric']\n\n    df['Event_name_clean'] = df['Event name'].apply(clean_event_name)\n\n    unique_before = df['Event name'].nunique()\n    unique_after = df['Event_name_clean'].nunique()\n\n    print(f\"Unique Event Names (Before): {unique_before:,}\")\n    print(f\"Unique Event Names (After):  {unique_after:,}\")\n    print(f\"Reduction: {((unique_before - unique_after) / unique_before) * 100:.2f}%\")\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:56:23.765870Z","iopub.execute_input":"2025-12-17T05:56:23.766184Z","iopub.status.idle":"2025-12-17T05:56:25.085906Z","shell.execute_reply.started":"2025-12-17T05:56:23.766164Z","shell.execute_reply":"2025-12-17T05:56:25.084825Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def engineer_features(df):\n    \"\"\"\n    Create cumulative and rolling features for ultramarathon dataset:\n    - cum_num_races, cum_avg_pace, cum_best_pace\n    - cum_total_distance, cum_avg_distance, cum_shortest_distance, cum_longest_distance\n    - cum_ws_finishes, recent_avg_distance, distance_gap_from_longest\n    - athlete_age\n    \"\"\"\n    \n    # Sort for cumulative calculations\n    df = df.sort_values(by=[\"Athlete ID\", \"Year of event\", \"Event name\"]).reset_index(drop=True)\n\n    # Cumulative number of races\n    df[\"cum_num_races\"] = df.groupby(\"Athlete ID\").cumcount()\n\n    # Cumulative average pace (excluding current race)\n    df[\"cum_avg_pace\"] = df.groupby(\"Athlete ID\")[\"pace_min_per_km\"].expanding().mean().shift(1).reset_index(level=0, drop=True)\n\n    # Cumulative best pace (excluding current race)\n    df[\"cum_best_pace\"] = df.groupby(\"Athlete ID\")[\"pace_min_per_km\"].expanding().min().shift(1).reset_index(level=0, drop=True)\n\n    # Cumulative distance stats\n    df[\"cum_total_distance\"] = df.groupby(\"Athlete ID\")[\"Event distance_numeric\"].cumsum()\n    df[\"cum_avg_distance\"] = df[\"cum_total_distance\"] / df[\"cum_num_races\"]\n    grp = df.groupby(\"Athlete ID\")[\"Event distance_numeric\"]\n    df[\"cum_shortest_distance\"] = grp.cummin()\n    df[\"cum_longest_distance\"] = grp.cummax()\n\n    # Cumulative Western States finishes\n    df[\"cum_ws_finishes\"] = (\n        df[\"Event name\"].eq(\"Western States\")# True for WS\n          .groupby(df[\"Athlete ID\"])# per athlete\n          .cumsum()# cumulative sum\n          .shift(1)# exclude current race\n          .fillna(0)# first race has 0\n          .astype(int)\n    )\n\n    # Recent average distance (rolling 3 races)\n    df[\"recent_avg_distance\"] = (\n        df.groupby(\"Athlete ID\")[\"Event distance_numeric\"]\n          .rolling(3, min_periods=1).mean()\n          .reset_index(level=0, drop=True)\n          .shift(1)\n    )\n\n    # Distance gap from longest\n    df[\"distance_gap_from_longest\"] = df[\"Event distance_numeric\"] - df[\"cum_longest_distance\"]\n\n    # Athlete age\n    df[\"athlete_age\"] = df[\"Year of event\"] - df[\"Athlete year of birth\"]\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:42:14.131409Z","iopub.execute_input":"2025-12-17T05:42:14.131770Z","iopub.status.idle":"2025-12-17T05:42:14.140271Z","shell.execute_reply.started":"2025-12-17T05:42:14.131743Z","shell.execute_reply":"2025-12-17T05:42:14.139307Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Test/Train Split","metadata":{}},{"cell_type":"code","source":"def split_train_test(df):\n    \"\"\"\n    Split dataset into train/test while preventing leakage from future races:\n    - Test: Western States 2022\n    - Train: all prior races of athletes in test set + other athletes\n    \"\"\"\n    \n    feature_cols = ['Year of event', 'Event number of finishers', 'Athlete gender', \n                    'Event distance_numeric', 'cum_num_races', 'cum_avg_pace', \n                    'cum_best_pace', 'cum_ws_finishes', 'cum_total_distance', \n                    'cum_avg_distance', 'cum_shortest_distance', 'cum_longest_distance', \n                    'recent_avg_distance', 'distance_gap_from_longest', 'athlete_age']\n\n    # Define test set: Western States 2022\n    df_test = df[\n        (df[\"Year of event\"] == 2022) &\n        (df[\"Event name\"].str.contains(\"Western States\", case=False, na=False))\n    ].copy()\n\n    # Identify runners in test set\n    ws_mask = (df[\"Year of event\"] == 2022) & df[\"Event name\"].str.contains(\"Western States\", case=False, na=False)\n    ws_2022_runners = df.loc[ws_mask, \"Athlete ID\"].unique()\n\n    # Cutoff cumulative races per athlete\n    ws_cutoffs = df[ws_mask].set_index(\"Athlete ID\")[\"cum_num_races\"]\n\n    # Map cutoff to all data\n    df[\"ws_cutoff\"] = df[\"Athlete ID\"].map(ws_cutoffs)  # NaN for runners not in WS 2022\n\n    # Keep only races before test race OR athletes not in test set\n    mask = (df[\"ws_cutoff\"].notna() & (df[\"cum_num_races\"] < df[\"ws_cutoff\"])) | df[\"ws_cutoff\"].isna()\n    df_train = df[mask].copy()\n\n    # Drop temporary column\n    df_train = df_train.drop(columns=\"ws_cutoff\")\n\n    print(\"Test set shape:\", df_test.shape)\n    print(\"Train set shape:\", df_train.shape)\n\n    return df_train, df_test, feature_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:42:18.967957Z","iopub.execute_input":"2025-12-17T05:42:18.968497Z","iopub.status.idle":"2025-12-17T05:42:18.977850Z","shell.execute_reply.started":"2025-12-17T05:42:18.968457Z","shell.execute_reply":"2025-12-17T05:42:18.976773Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Feature and Target Preparation","metadata":{}},{"cell_type":"code","source":"def apply_smoothed_target_encoding(train_df, test_df, column='Event_name_clean', target='pace_min_per_km', m=10):\n    \"\"\"\n    Computes smoothed target encoding for the event names.\n    m is the 'smoothing' factor (higher m = more conservative).\n    \"\"\"\n    # Calculate global mean from training data only (No leakage!)\n    global_mean = train_df[target].mean()\n\n    # Calculate count and mean for each race\n    agg = train_df.groupby(column)[target].agg(['count', 'mean'])\n    \n    # Calculate the smoothed value\n    # Formula: (count * mean + m * global_mean) / (count + m)\n    smooth_weights = (agg['count'] * agg['mean'] + m * global_mean) / (agg['count'] + m)\n    \n    # Map the weights back to the dataframes\n    train_df['Race_Pace_Mean_Encoded'] = train_df[column].map(smooth_weights).fillna(global_mean)\n    test_df['Race_Pace_Mean_Encoded'] = test_df[column].map(smooth_weights).fillna(global_mean)\n    \n    return train_df, test_df\n\ndef prepare_model_data(df_train, df_test, feature_cols, target_col='pace_min_per_km'):\n    \"\"\"\n    Prepare train/test datasets for modeling:\n    - Select features\n    - One-hot encode categorical variables\n    - Align columns\n    - Define target\n    - Clean infinities\n    \"\"\"\n    \n    df_train, df_test = apply_difficulty_encoding(df_train, df_test)\n    \n    # Select features\n    X_train = df_train[feature_cols].copy()\n    X_test  = df_test[feature_cols].copy()\n\n    # One-hot encode categorical variables (gender)\n    X_train = pd.get_dummies(X_train, columns=['Athlete gender'], drop_first=True)\n    X_test  = pd.get_dummies(X_test,  columns=['Athlete gender'], drop_first=True)\n\n    # Align columns\n    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n\n    # Define target\n    y_train = df_train[target_col]\n    y_test  = df_test[target_col]\n\n    # Clean infinities\n    X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n    X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    # Fill NaNs (including former infinities) with -1\n    X_train.fillna(-1, inplace=True)\n    X_test.fillna(-1, inplace=True)\n\n\n    print(\"Shapes:\", X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n    return X_train, X_test, y_train, y_test\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-18T03:42:25.091Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\ndef train_evaluate_lgbm(X_train, y_train, X_test, y_test, params=None):\n    \"\"\"\n    Train a LightGBM regressor and evaluate performance on test set.\n    Returns the fitted model and predictions.\n    \"\"\"\n    if params is None:\n        params = {\n            \"n_estimators\": 500,\n            \"learning_rate\": 0.05,\n            \"num_leaves\": 64,\n            \"max_depth\": -1,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"random_state\": 42,\n            \"verbose\": -1\n        }\n\n    # Initialize model\n    model = lgb.LGBMRegressor(**params)\n\n    # Fit model\n    model.fit(X_train, y_train)\n\n    # Predict\n    y_pred = model.predict(X_test)\n\n    # Evaluate\n    mae = mean_absolute_error(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    r2  = r2_score(y_test, y_pred)\n\n    print(f\"MAE: {mae:.4f}\")\n    print(f\"MSE: {mse:.4f}\")\n    print(f\"R2 : {r2:.4f}\")\n\n    return model, y_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:56:37.725509Z","iopub.execute_input":"2025-12-17T05:56:37.725995Z","iopub.status.idle":"2025-12-17T05:56:37.733183Z","shell.execute_reply.started":"2025-12-17T05:56:37.725959Z","shell.execute_reply":"2025-12-17T05:56:37.732087Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#Pipeline\nPATH = \"/kaggle/input/the-big-dataset-of-ultra-marathon-running/TWO_CENTURIES_OF_UM_RACES.csv\"\n\n# -----------------------------\n# Imports\n# -----------------------------\nimport pandas as pd\n\n# Assume all your functions are already defined:\n# clean_data(), engineer_features(), split_train_test(), prepare_model_data(), train_evaluate_lgbm()\n\n# -----------------------------\n# Pipeline Function\n# -----------------------------\ndef run_pipeline(raw_csv_path):\n    \"\"\"\n    Full Kaggle-ready ML pipeline for ultra-marathon pace prediction:\n    1. Load raw data\n    2. Clean data\n    3. Feature engineering\n    4. Train/Test split\n    5. Prepare features & target\n    6. Train & evaluate LightGBM model\n    \"\"\"\n    # 1. Load data\n    df = load_raw_data(raw_csv_path)\n    print(\"Raw data shape:\", df.shape)\n\n    # 2. Clean data\n    df_clean = clean_data(df)\n    print(\"After cleaning:\", df_clean.shape)\n\n    # 3. Feature engineering\n    df_features = engineer_features(df_clean)\n    print(\"After feature engineering:\", df_features.shape)\n\n    # 4. Train/Test split\n    df_train, df_test, feature_cols = split_train_test(df_features)\n    print(\"Train/Test split done. Train:\", df_train.shape, \"Test:\", df_test.shape)\n\n    # 5. Prepare features & target\n    X_train, X_test, y_train, y_test = prepare_model_data(df_train, df_test, feature_cols)\n    print(\"Feature & target preparation done. X_train:\", X_train.shape)\n\n    # 6. Train & evaluate model\n    model, y_pred = train_evaluate_lgbm(X_train, y_train, X_test, y_test)\n\n    return model, X_train, X_test, y_train, y_test, y_pred\n\n# -----------------------------\n# Run the pipeline\n# -----------------------------\nmodel, X_train, X_test, y_train, y_test, y_pred = run_pipeline(PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:56:43.362114Z","iopub.execute_input":"2025-12-17T05:56:43.362442Z","execution_failed":"2025-12-18T03:42:25.090Z"}},"outputs":[{"name":"stdout","text":"Raw data shape: (7461195, 13)\nUnique Event Names (Before): 20,058\nUnique Event Names (After):  19,587\nReduction: 2.35%\nAfter cleaning: (6255867, 15)\nAfter feature engineering: (6255867, 26)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"Test set shape: (301, 26)\nTrain set shape: (6255548, 26)\nTrain/Test split done. Train: (6255548, 26) Test: (301, 26)\nShapes: (6255548, 15) (6255548,) (301, 15) (301,)\nFeature & target preparation done. X_train: (6255548, 15)\n","output_type":"stream"}],"execution_count":null}]}